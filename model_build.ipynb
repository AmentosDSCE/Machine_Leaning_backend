{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca3dac2f-e22e-4d2b-8673-c26c27c7531e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a105f367-0020-41e0-a7c4-ba8251888579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2d14b9-703c-4845-a05d-52d5aabf0340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3ece1b7-88ee-4e68-ba97-5c1bfa593138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image\n",
      "  Downloading image-1.5.33.tar.gz (15 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pillow in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from image) (9.2.0)\n",
      "Collecting django\n",
      "  Downloading Django-4.2.1-py3-none-any.whl (8.0 MB)\n",
      "     ---------------------------------------- 8.0/8.0 MB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from image) (1.16.0)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     -------------------------------------- 341.8/341.8 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting sqlparse>=0.3.1\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "     -------------------------------------- 41.2/41.2 kB 967.0 kB/s eta 0:00:00\n",
      "Collecting asgiref<4,>=3.6.0\n",
      "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from asgiref<4,>=3.6.0->django->image) (4.3.0)\n",
      "Building wheels for collected packages: image\n",
      "  Building wheel for image (setup.py): started\n",
      "  Building wheel for image (setup.py): finished with status 'done'\n",
      "  Created wheel for image: filename=image-1.5.33-py2.py3-none-any.whl size=19483 sha256=6cc7bb32f7f6d977b4e7a1ac15bc1991f615d8e54503a7d33407419cfa29290e\n",
      "  Stored in directory: c:\\users\\dheer\\appdata\\local\\pip\\cache\\wheels\\14\\4c\\7c\\d9b5c35a149d3bc8c72c7e92372913ff7dac9c6bd94bd1b8c9\n",
      "Successfully built image\n",
      "Installing collected packages: tzdata, sqlparse, asgiref, django, image\n",
      "Successfully installed asgiref-3.7.2 django-4.2.1 image-1.5.33 sqlparse-0.4.4 tzdata-2023.3\n"
     ]
    }
   ],
   "source": [
    "!pip install image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b68e6a4-5df9-4a15-abb7-484baff602b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c9038f2-a63a-4f37-968e-9fc438bf8cf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wheel.pep425tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3280\\3775162648.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mwheel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpep425tags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wheel.pep425tags'"
     ]
    }
   ],
   "source": [
    "import wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a82a77b-9888-494a-b9c9-49087dd44d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchvision import datasets ,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f51ec07c-3332-4492-98be-48854868a7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement grp (from versions: none)\n",
      "ERROR: No matching distribution found for grp\n"
     ]
    }
   ],
   "source": [
    "!pip install grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7da766d0-8f2e-4323-80d8-b6a5595e2a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02a2e5d3-660e-447d-81c1-a7f2eaa72b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting celery==5.2.0\n",
      "  Downloading celery-5.2.0-py3-none-any.whl (404 kB)\n",
      "     -------------------------------------- 404.1/404.1 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: billiard<4.0,>=3.6.4.0 in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from celery==5.2.0) (3.6.4.0)\n",
      "Requirement already satisfied: click-didyoumean>=0.0.3 in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from celery==5.2.0) (0.3.0)\n",
      "Requirement already satisfied: vine<6.0,>=5.0.0 in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from celery==5.2.0) (5.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from celery==5.2.0) (63.4.1)\n",
      "Requirement already satisfied: kombu<6.0,>=5.2.1 in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from celery==5.2.0) (5.2.4)\n",
      "Requirement already satisfied: click<9.0,>=8.0 in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from celery==5.2.0) (8.0.4)\n",
      "Requirement already satisfied: click-repl>=0.2.0 in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from celery==5.2.0) (0.2.0)\n",
      "Requirement already satisfied: click-plugins>=1.1.1 in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from celery==5.2.0) (1.1.1)\n",
      "Requirement already satisfied: pytz>dev in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from celery==5.2.0) (2022.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from click<9.0,>=8.0->celery==5.2.0) (0.4.5)\n",
      "Requirement already satisfied: prompt-toolkit in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from click-repl>=0.2.0->celery==5.2.0) (3.0.20)\n",
      "Requirement already satisfied: six in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from click-repl>=0.2.0->celery==5.2.0) (1.16.0)\n",
      "Requirement already satisfied: amqp<6.0.0,>=5.0.9 in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from kombu<6.0,>=5.2.1->celery==5.2.0) (5.1.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\dheer\\anaconda3\\lib\\site-packages (from prompt-toolkit->click-repl>=0.2.0->celery==5.2.0) (0.2.5)\n",
      "Installing collected packages: celery\n",
      "  Attempting uninstall: celery\n",
      "    Found existing installation: celery 5.2.7\n",
      "    Uninstalling celery-5.2.7:\n",
      "      Successfully uninstalled celery-5.2.7\n",
      "Successfully installed celery-5.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install celery==5.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2387132c-4933-41c6-933f-f3ec1ee98c44",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'grp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3280\\3293374364.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mhelper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\helper\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhelper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munix\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplatform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2.5.0'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\helper\\unix.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0matexit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgrp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'grp'"
     ]
    }
   ],
   "source": [
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06954bbd-be7e-4519-bed1-5fa4ad368339",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'grp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3280\\1222733890.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgrp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'grp'"
     ]
    }
   ],
   "source": [
    "import grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580af919-9116-4617-b350-07fe8d607991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65eef025-7751-4475-bd44-1a7924b08113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_extension(id, extension):\n",
    "    PIL.Image.EXTENSION[extension.lower()] = id.upper()\n",
    "PIL.Image.register_extension = register_extension\n",
    "def register_extensions(id, extensions):\n",
    "    for extension in extensions:\n",
    "        register_extension(id, extension)\n",
    "PIL.Image.register_extensions = register_extensions\n",
    "\n",
    "from PIL import Image\n",
    "def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()\n",
    "Image.register_extension = register_extension\n",
    "def register_extensions(id, extensions): \n",
    "  for extension in extensions: register_extension(id, extension)\n",
    "Image.register_extensions = register_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2c26724-75b8-410b-a709-13e967d4a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"archive/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f17d864f-13f7-4177-9087-3aa8aedd3ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.RandomResizedCrop(224),\n",
    "                                     # transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "061c5378-526d-4aac-a8f0-fa11d36d6df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.RandomResizedCrop(224),\n",
    "                                     # transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e8c2cca-9705-4d0f-b673-4c67c64154c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(data+\"/train\", transform=transform_train)\n",
    "test_data = datasets.ImageFolder(data+\"/valid\", transform = transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8ad8723-2dc8-423e-8a76-03aa588a8013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(test_data.classes)\n",
    "print(n_classes)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e72f8f6-4bae-499e-b2d6-85dee369e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True, num_workers=2)\n",
    "dataloader_test = torch.utils.data.DataLoader(test_data, batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb59f3d0-46ec-4b13-bc66-036954059a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "797d81e7-d8e8-4463-8f81-48433788d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mean = [0.485, 0.456, 0.406]\n",
    "norm_std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "257f81b5-f3c7-4c4e-b4f9-f13a9c000ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_numpy(image, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.grid(False)\n",
    "    \n",
    "    image = image.transpose((1, 2, 0))\n",
    "    \n",
    "    mean = np.array(norm_mean)\n",
    "    std = np.array(norm_std)\n",
    "    image = std * image + mean\n",
    "    \n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e579ca3-82e4-40ff-a42a-dfbfb1484995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels = next(iter(dataloader_train))\n",
    "# imshow_numpy(images[0].numpy())\n",
    "# print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c677c024-4ca5-4ef8-b39d-d46229538335",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95e52ccd-c6e2-493f-bb21-83b4a943c31d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "imshow_numpy() missing 1 required positional argument: 'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27404\\3160609063.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimshow_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: imshow_numpy() missing 1 required positional argument: 'image'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5482d4-c944-4966-870f-1e47a5969926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imshow_numpy(images[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "277edcef-111c-4dee-9037-cc8226049df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images[0].numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9cb97b4-d7bf-4c4f-b113-23e0d91cd29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.  Training on CPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b23c020f-1812-4bf8-af6c-4c88bfd0b8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dheer\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dheer\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\dheer/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [03:14<00:00, 527kB/s] \n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.models as models\n",
    "model = models.resnet50(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5d30fde-58d3-4d8a-beb2-64c25f5deb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dheer\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dheer\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to C:\\Users\\dheer/.cache\\torch\\hub\\checkpoints\\resnet101-63fe2227.pth\n",
      "100%|██████████| 171M/171M [04:03<00:00, 735kB/s]  \n"
     ]
    }
   ],
   "source": [
    "model_2 = models.resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08996e7d-3152-4243-8ed8-53e034fbe6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dc2cd4e-1ccc-45bf-9b87-0952337d89f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74c5dafa-8021-4578-99d1-7e4704e7f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import seaborn as sn\n",
    "from torch import optim\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn import svm, datasets\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13cfbf44-120d-4499-bf3c-57655f8337a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83940c97-b011-41da-a6e8-f11b4473e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b4d6884-2214-48cf-bad3-babcd85c5848",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(nn.Linear(2048, 256),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.4),\n",
    "                                 nn.Linear(256,128),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.4),\n",
    "                                 nn.Linear(128,38),\n",
    "                                 nn.LogSoftmax(dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94bec654-f454-47e8-9a07-fa399bfa5773",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr = 0.00008)\n",
    "\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2b4fcc9-5089-4c5c-9179-1d3da916fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "valid_loss_min = np.Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c9cb303-2af1-486c-b2dc-f929ba068446",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randint(0, n_classes, (batch_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adc6a36c-e2c6-4076-81fb-3d857c1101bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(preds, labels, conf_matrix, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    preds = torch.argmax(preds, 1)\n",
    "    for p, t in zip(preds, labels):\n",
    "        conf_matrix[p, t] += 1\n",
    "\n",
    "    TP = conf_matrix.diag()\n",
    "    for c in range(n_classes):\n",
    "        idx = torch.ones(n_classes).byte()\n",
    "        idx[c] = 0\n",
    "        TN = conf_matrix[idx.nonzero()[:,None], idx.nonzero()].sum()\n",
    "        FP = conf_matrix[c, idx].sum()\n",
    "        FN = conf_matrix[idx, c].sum()\n",
    "\n",
    "        Recall = (TP[c] / (TP[c]+FN))\n",
    "        precision = (TP[c] / (TP[c]+FP))\n",
    "        f1 = (2 * ((precision * Recall)/(precision + Recall)))\n",
    "\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c61b0233-76eb-4cb2-bef0-02b0a8363985",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = torch.zeros(n_classes, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fcc04eb5-fa4b-46d7-b1b5-6fc9eec09150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first loop\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n",
      "second loop end\n",
      "second loop begin\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14660\\1654452657.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m#loss = torch.nn.functional.nll_loss(torch.log(p), y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    print(\"first loop\")\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    \n",
    "\n",
    " \n",
    "    for images, labels in dataloader_train:\n",
    "        print(\"second loop begin\")\n",
    "        #steps += 1\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        output = model.forward(images)\n",
    "        conf_matrix = confusion_matrix(output, labels, conf_matrix)\n",
    "        p = torch.nn.functional.softmax(output, dim=1)\n",
    "        prediction = torch.argmax(p, dim=1)\n",
    "        #loss = torch.nn.functional.nll_loss(torch.log(p), y)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_loss += loss.item()*images.size(0)\n",
    "        print(\"second loop end\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #vis.line(X=torch.ones((1,1)).cpu()*epoch, Y=torch.Tensor([train_loss]).unsqueeze(0).cpu(),win=loss_window,update='append')    \n",
    "    \n",
    "  #if steps % print_every == 0:\n",
    "    print(\"out of second loop\")\n",
    "    valid_loss = 0\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "  #print(conf_matrix)\n",
    "    TP = conf_matrix.diag()\n",
    "    for c in range(n_classes):\n",
    "        print(\"third loop start\")\n",
    "        idx = torch.ones(n_classes).byte()\n",
    "        idx[c] = 0\n",
    "        TN = conf_matrix[idx.nonzero()[:,None], idx.nonzero()].sum()\n",
    "        FP = conf_matrix[c, idx].sum()\n",
    "        FN = conf_matrix[idx, c].sum()\n",
    "\n",
    "        Recall = (TP[c] / (TP[c]+FN))\n",
    "        precision = (TP[c] / (TP[c]+FP))\n",
    "        f1 = (2 * ((precision * Recall)/(precision + Recall)))\n",
    "        print(\"third loop end\")\n",
    "    print(\"out of third loop\")\n",
    "      #print('Class {}\\nTP {}, TN {}, FP {}, FN {}'.format(c, TP[c], TN, FP, FN))\n",
    "      #print('Sensitivity = {}'.format(sensitivity))\n",
    "      #print('Specificity = {}'.format(specificity))\n",
    "    #return TP[C], TN, FP, FN, sensitivity, specificity\n",
    "    \n",
    "  \n",
    "    for images, labels in dataloader_test:\n",
    "        print(\"in fourth loop\")\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "      #if train_on_gpu:\n",
    "      #      images, labels = data.cuda(), target.cuda()\n",
    "\n",
    "            output = model.forward(images)\n",
    "            conf_matrix = confusion_matrix(output, labels, conf_matrix)\n",
    "            p = torch.nn.functional.softmax(output, dim=1)\n",
    "            prediction = torch.argmax(p, dim=1)\n",
    "            loss = criterion(output, labels)\n",
    "          \n",
    "            valid_loss += loss.item()*images.size(0)\n",
    "      \n",
    "            ps = torch.exp(output)\n",
    "         \n",
    "            top_p, top_class = ps.topk(1, dim = 1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "            print(\"end of fourth loop\")\n",
    "    print(\"out side of 4rth loop\")\n",
    "    \n",
    "      \n",
    "  # calculate average losses\n",
    "    train_loss = train_loss/len(dataloader_train.dataset)\n",
    "    valid_loss = valid_loss/len(dataloader_test.dataset)\n",
    "        \n",
    "  # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "  # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "        valid_loss_min = valid_loss\n",
    "  \n",
    "    print(conf_matrix)\n",
    "    plt.imshow(conf_matrix)\n",
    "    TP = conf_matrix.diag()\n",
    "    for c in range(n_classes):\n",
    "        print(\"inside 5th loop\")\n",
    "        idx = torch.ones(n_classes).byte()\n",
    "        idx[c] = 0\n",
    "        TN = conf_matrix[idx.nonzero()[:,None], idx.nonzero()].sum()\n",
    "        FP = conf_matrix[c, idx].sum()\n",
    "        FN = conf_matrix[idx, c].sum()\n",
    "\n",
    "        Recall = (TP[c] / (TP[c]+FN))\n",
    "        precision = (TP[c] / (TP[c]+FP))\n",
    "        f1 = (2 * ((precision * Recall)/(precision + Recall)))\n",
    "      \n",
    "        print('Class {}\\nTP {}, TN {}, FP {}, FN {}'.format(c, TP[c], TN, FP, FN))\n",
    "        print('Recall = {}'.format(Recall))\n",
    "        print('Precision = {}'.format(precision))\n",
    "        print('F1 Score = {}'.format(f1))\n",
    "        print(\"end of 5th loop\")\n",
    "    print(\"outside 5th loop\")\n",
    "\n",
    "    print(\"Accuracy: {:.4f}.. \" .format(accuracy/len(dataloader_test)))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b7f8b7-4446-436f-87d9-9dbf2c5ed935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
